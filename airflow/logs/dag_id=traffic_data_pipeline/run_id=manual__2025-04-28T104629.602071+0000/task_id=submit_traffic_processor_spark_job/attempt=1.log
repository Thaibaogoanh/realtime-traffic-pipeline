[2025-04-28T10:46:32.739+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: traffic_data_pipeline.submit_traffic_processor_spark_job manual__2025-04-28T10:46:29.602071+00:00 [queued]>
[2025-04-28T10:46:32.761+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: traffic_data_pipeline.submit_traffic_processor_spark_job manual__2025-04-28T10:46:29.602071+00:00 [queued]>
[2025-04-28T10:46:32.762+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-04-28T10:46:32.790+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): submit_traffic_processor_spark_job> on 2025-04-28 10:46:29.602071+00:00
[2025-04-28T10:46:32.800+0000] {standard_task_runner.py:60} INFO - Started process 11172 to run task
[2025-04-28T10:46:32.817+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'traffic_data_pipeline', 'submit_traffic_processor_spark_job', 'manual__2025-04-28T10:46:29.602071+00:00', '--job-id', '51', '--raw', '--subdir', 'DAGS_FOLDER/traffic_pipeline_dag.py', '--cfg-path', '/tmp/tmp23ru9xh7']
[2025-04-28T10:46:32.827+0000] {standard_task_runner.py:88} INFO - Job 51: Subtask submit_traffic_processor_spark_job
[2025-04-28T10:46:32.971+0000] {task_command.py:423} INFO - Running <TaskInstance: traffic_data_pipeline.submit_traffic_processor_spark_job manual__2025-04-28T10:46:29.602071+00:00 [running]> on host 02173e944d7b
[2025-04-28T10:46:33.186+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='traffic_data_pipeline' AIRFLOW_CTX_TASK_ID='submit_traffic_processor_spark_job' AIRFLOW_CTX_EXECUTION_DATE='2025-04-28T10:46:29.602071+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-04-28T10:46:29.602071+00:00'
[2025-04-28T10:46:33.201+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-04-28T10:46:33.206+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', '\n            echo "--- Checking Line Endings for processor.py ---"\n            cat -e /opt/spark/app/processor.py | head -n 10\n            echo "--- Finished Checking Line Endings ---"\n            echo "Setting PYTHONPATH..."\n            PYTHON_USER_SITE="/home/***/.local/lib/python3.10/site-packages"\n            export PYTHONPATH="${PYTHON_USER_SITE}:${PYTHONPATH:-}"\n            echo "Using PYTHONPATH=$PYTHONPATH"\n            echo "Exporting other environment variables..."\n            export KAFKA_BROKERS_INTERNAL="$KAFKA_BROKERS_INTERNAL" && \\\n            export KAFKA_TOPIC="$KAFKA_TOPIC" && \\\n            export SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL" && \\\n            export REDIS_HOST="$REDIS_HOST" && \\\n            export CLICKHOUSE_HOST="$CLICKHOUSE_HOST" && \\\n            export CLICKHOUSE_NATIVE_PORT="$CLICKHOUSE_NATIVE_PORT" && \\\n            export MINIO_ENDPOINT="$MINIO_ENDPOINT" && \\\n            export MINIO_ACCESS_KEY="$MINIO_ACCESS_KEY" && \\\n            export MINIO_SECRET_KEY="$MINIO_SECRET_KEY" && \\\n            export MINIO_BUCKET="$MINIO_BUCKET" && \\\n            CHECKPOINT_LOCATION_VAR="s3a://${MINIO_BUCKET:-traffic-data}/checkpoints_***/traffic_processing_pipeline" && \\\n            export CHECKPOINT_LOCATION="$CHECKPOINT_LOCATION_VAR" && \\\n            export PYSPARK_PYTHON=/usr/local/bin/python3.10 && \\\n            echo "--- Running Spark Submit ---" && \\\n            spark-submit \\\n            --master local[*] \\\n            --deploy-mode client \\\n            --conf spark.sql.streaming.schemaInference=true \\\n            --conf spark.hadoop.fs.s3a.endpoint="$MINIO_ENDPOINT" \\\n            --conf spark.hadoop.fs.s3a.access.key="$MINIO_ACCESS_KEY" \\\n            --conf spark.hadoop.fs.s3a.secret.key="$MINIO_SECRET_KEY" \\\n            --conf spark.hadoop.fs.s3a.path.style.access=true \\\n            --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem \\\n            --conf spark.sql.avro.schemaRegistryUrl="$SCHEMA_REGISTRY_URL" \\\n            /opt/spark/app/processor.py\n            ']
[2025-04-28T10:46:33.229+0000] {subprocess.py:86} INFO - Output:
[2025-04-28T10:46:33.237+0000] {subprocess.py:93} INFO - --- Checking Line Endings for processor.py ---
[2025-04-28T10:46:33.246+0000] {subprocess.py:93} INFO - import os$
[2025-04-28T10:46:33.246+0000] {subprocess.py:93} INFO - import json$
[2025-04-28T10:46:33.247+0000] {subprocess.py:93} INFO - import math$
[2025-04-28T10:46:33.248+0000] {subprocess.py:93} INFO - from datetime import datetime$
[2025-04-28T10:46:33.249+0000] {subprocess.py:93} INFO - import traceback$
[2025-04-28T10:46:33.250+0000] {subprocess.py:93} INFO - from typing import Optional$
[2025-04-28T10:46:33.251+0000] {subprocess.py:93} INFO - $
[2025-04-28T10:46:33.252+0000] {subprocess.py:93} INFO - # Import thM-FM-0 viM-aM-;M-^Gn cM-aM-:M-'n thiM-aM-:M-?t cho Pandas UDF$
[2025-04-28T10:46:33.252+0000] {subprocess.py:93} INFO - import pandas as pd$
[2025-04-28T10:46:33.253+0000] {subprocess.py:93} INFO - from pyspark.sql import SparkSession$
[2025-04-28T10:46:33.254+0000] {subprocess.py:93} INFO - --- Finished Checking Line Endings ---
[2025-04-28T10:46:33.255+0000] {subprocess.py:93} INFO - Setting PYTHONPATH...
[2025-04-28T10:46:33.255+0000] {subprocess.py:93} INFO - Using PYTHONPATH=/home/***/.local/lib/python3.10/site-packages:
[2025-04-28T10:46:33.256+0000] {subprocess.py:93} INFO - Exporting other environment variables...
[2025-04-28T10:46:33.257+0000] {subprocess.py:93} INFO - --- Running Spark Submit ---
[2025-04-28T10:46:33.317+0000] {subprocess.py:93} INFO - /opt/spark/bin/load-spark-env.sh: line 68: ps: command not found
[2025-04-28T10:46:45.707+0000] {subprocess.py:93} INFO - --- PySpark Script Dependencies Imported ---
[2025-04-28T10:46:45.710+0000] {subprocess.py:93} INFO - --- Starting Spark Streaming Traffic Processor ---
[2025-04-28T10:46:45.712+0000] {subprocess.py:93} INFO - Reading from Kafka: kafk-1:9092,kafk-2:9092,kafk-3:9092 / Topic: raw_traffic_data
[2025-04-28T10:46:45.712+0000] {subprocess.py:93} INFO - Avro Schema File: /opt/spark/schemas/raw_traffic_event.avsc
[2025-04-28T10:46:45.714+0000] {subprocess.py:93} INFO - Writing state to Redis: redis:6379
[2025-04-28T10:46:45.715+0000] {subprocess.py:93} INFO - Writing history to ClickHouse: clickhouse-server:8123 (DB: traffic_db)
[2025-04-28T10:46:45.716+0000] {subprocess.py:93} INFO - Writing Parquet to MinIO Bucket: s3a://traffic-data/
[2025-04-28T10:46:45.717+0000] {subprocess.py:93} INFO - Checkpoint Location Base: s3a://traffic-data/checkpoints_***/traffic_processing_pipeline
[2025-04-28T10:46:46.046+0000] {subprocess.py:93} INFO - 25/04/28 10:46:46 INFO SparkContext: Running Spark version 3.3.4
[2025-04-28T10:46:46.182+0000] {subprocess.py:93} INFO - 25/04/28 10:46:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-04-28T10:46:46.380+0000] {subprocess.py:93} INFO - 25/04/28 10:46:46 INFO ResourceUtils: ==============================================================
[2025-04-28T10:46:46.381+0000] {subprocess.py:93} INFO - 25/04/28 10:46:46 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-04-28T10:46:46.382+0000] {subprocess.py:93} INFO - 25/04/28 10:46:46 INFO ResourceUtils: ==============================================================
[2025-04-28T10:46:46.382+0000] {subprocess.py:93} INFO - 25/04/28 10:46:46 INFO SparkContext: Submitted application: TrafficProcessorDE
[2025-04-28T10:46:46.424+0000] {subprocess.py:93} INFO - 25/04/28 10:46:46 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-04-28T10:46:46.441+0000] {subprocess.py:93} INFO - 25/04/28 10:46:46 INFO ResourceProfile: Limiting resource is cpu
[2025-04-28T10:46:46.443+0000] {subprocess.py:93} INFO - 25/04/28 10:46:46 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-04-28T10:46:46.630+0000] {subprocess.py:93} INFO - 25/04/28 10:46:46 INFO SecurityManager: Changing view acls to: ***
[2025-04-28T10:46:46.635+0000] {subprocess.py:93} INFO - 25/04/28 10:46:46 INFO SecurityManager: Changing modify acls to: ***
[2025-04-28T10:46:46.637+0000] {subprocess.py:93} INFO - 25/04/28 10:46:46 INFO SecurityManager: Changing view acls groups to:
[2025-04-28T10:46:46.639+0000] {subprocess.py:93} INFO - 25/04/28 10:46:46 INFO SecurityManager: Changing modify acls groups to:
[2025-04-28T10:46:46.641+0000] {subprocess.py:93} INFO - 25/04/28 10:46:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(***); groups with view permissions: Set(); users  with modify permissions: Set(***); groups with modify permissions: Set()
[2025-04-28T10:46:48.026+0000] {subprocess.py:93} INFO - 25/04/28 10:46:48 INFO Utils: Successfully started service 'sparkDriver' on port 40633.
[2025-04-28T10:46:48.218+0000] {subprocess.py:93} INFO - 25/04/28 10:46:48 INFO SparkEnv: Registering MapOutputTracker
[2025-04-28T10:46:48.458+0000] {subprocess.py:93} INFO - 25/04/28 10:46:48 INFO SparkEnv: Registering BlockManagerMaster
[2025-04-28T10:46:48.556+0000] {subprocess.py:93} INFO - 25/04/28 10:46:48 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-04-28T10:46:48.564+0000] {subprocess.py:93} INFO - 25/04/28 10:46:48 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-04-28T10:46:48.609+0000] {subprocess.py:93} INFO - 25/04/28 10:46:48 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-04-28T10:46:48.672+0000] {subprocess.py:93} INFO - 25/04/28 10:46:48 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8e9e78ec-f36e-4972-a4aa-30151c8c2ce6
[2025-04-28T10:46:48.785+0000] {subprocess.py:93} INFO - 25/04/28 10:46:48 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-04-28T10:46:48.837+0000] {subprocess.py:93} INFO - 25/04/28 10:46:48 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-04-28T10:46:49.636+0000] {subprocess.py:93} INFO - 25/04/28 10:46:49 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[2025-04-28T10:46:49.672+0000] {subprocess.py:93} INFO - 25/04/28 10:46:49 INFO Utils: Successfully started service 'SparkUI' on port 4041.
[2025-04-28T10:46:50.180+0000] {subprocess.py:93} INFO - 25/04/28 10:46:50 INFO Executor: Starting executor ID driver on host 02173e944d7b
[2025-04-28T10:46:50.208+0000] {subprocess.py:93} INFO - 25/04/28 10:46:50 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2025-04-28T10:46:50.267+0000] {subprocess.py:93} INFO - 25/04/28 10:46:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39381.
[2025-04-28T10:46:50.271+0000] {subprocess.py:93} INFO - 25/04/28 10:46:50 INFO NettyBlockTransferService: Server created on 02173e944d7b:39381
[2025-04-28T10:46:50.280+0000] {subprocess.py:93} INFO - 25/04/28 10:46:50 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-04-28T10:46:50.307+0000] {subprocess.py:93} INFO - 25/04/28 10:46:50 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 02173e944d7b, 39381, None)
[2025-04-28T10:46:50.312+0000] {subprocess.py:93} INFO - 25/04/28 10:46:50 INFO BlockManagerMasterEndpoint: Registering block manager 02173e944d7b:39381 with 434.4 MiB RAM, BlockManagerId(driver, 02173e944d7b, 39381, None)
[2025-04-28T10:46:50.315+0000] {subprocess.py:93} INFO - 25/04/28 10:46:50 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 02173e944d7b, 39381, None)
[2025-04-28T10:46:50.318+0000] {subprocess.py:93} INFO - 25/04/28 10:46:50 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 02173e944d7b, 39381, None)
[2025-04-28T10:46:51.440+0000] {subprocess.py:93} INFO - Spark Session created. Spark version: 3.3.4
[2025-04-28T10:46:51.441+0000] {subprocess.py:93} INFO - Using PySpark version: 3.3.4
[2025-04-28T10:46:51.442+0000] {subprocess.py:93} INFO - Broadcasting segments data...
[2025-04-28T10:46:51.923+0000] {subprocess.py:93} INFO - Segments data broadcasted successfully.
[2025-04-28T10:46:52.642+0000] {subprocess.py:93} INFO - /opt/spark/python/lib/pyspark.zip/pyspark/sql/pandas/functions.py:394: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.
[2025-04-28T10:46:52.643+0000] {subprocess.py:93} INFO - Pandas UDF for map matching defined.
[2025-04-28T10:46:52.645+0000] {subprocess.py:93} INFO - Setting up Kafka stream reader...
[2025-04-28T10:46:52.646+0000] {subprocess.py:93} INFO - Kafka Read Options: {'kafka.bootstrap.servers': 'kafk-1:9092,kafk-2:9092,kafk-3:9092', 'subscribe': 'raw_traffic_data', 'startingOffsets': 'earliest', 'failOnDataLoss': 'false'}
[2025-04-28T10:46:59.445+0000] {subprocess.py:93} INFO - Kafka stream reader loaded.
[2025-04-28T10:46:59.445+0000] {subprocess.py:93} INFO - Reading Avro schema from file: /opt/spark/schemas/raw_traffic_event.avsc
[2025-04-28T10:46:59.448+0000] {subprocess.py:93} INFO - Successfully read Avro schema string from file.
[2025-04-28T10:46:59.449+0000] {subprocess.py:93} INFO - Setting up Avro deserialization...
[2025-04-28T10:46:59.669+0000] {subprocess.py:93} INFO - Avro deserialization step defined.
[2025-04-28T10:46:59.670+0000] {subprocess.py:93} INFO - Defining data processing steps...
[2025-04-28T10:46:59.994+0000] {subprocess.py:93} INFO - Data processing steps defined.
[2025-04-28T10:46:59.995+0000] {subprocess.py:93} INFO - Using checkpoint location: s3a://traffic-data/checkpoints_***/traffic_processing_pipeline/traffic_processing_pipeline_debug2
[2025-04-28T10:46:59.996+0000] {subprocess.py:93} INFO - Starting streaming query...
[2025-04-28T10:47:00.241+0000] {subprocess.py:93} INFO - 25/04/28 10:47:00 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
[2025-04-28T10:47:01.514+0000] {subprocess.py:93} INFO - 25/04/28 10:47:01 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[2025-04-28T10:47:01.773+0000] {subprocess.py:93} INFO - Streaming query 'traffic_processing_pipeline_debug2' started successfully.
[2025-04-28T10:47:06.948+0000] {subprocess.py:93} INFO - 25/04/28 10:47:06 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:06.949+0000] {subprocess.py:93} INFO - 25/04/28 10:47:06 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:06.949+0000] {subprocess.py:93} INFO - 25/04/28 10:47:06 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.332+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.333+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.333+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.334+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.334+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.335+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.335+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.336+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.336+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.337+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.337+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.338+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.338+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.339+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.339+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.340+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.340+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.341+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.341+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.342+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.342+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.343+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.343+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.344+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.344+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.345+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.345+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.346+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.346+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.347+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.347+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.348+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.348+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.349+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.349+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.350+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.350+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.350+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.351+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.351+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.352+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.352+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.352+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.353+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.354+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.354+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.355+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.355+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.355+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.356+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.356+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.356+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.357+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.357+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.358+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.359+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.359+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.360+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.360+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.361+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.361+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.362+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.362+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.363+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.363+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.364+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.365+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.366+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.366+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.367+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.367+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.368+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.368+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.368+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.369+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.369+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.370+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.370+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.370+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.371+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.371+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.372+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.372+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.373+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.374+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.375+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.375+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.376+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.376+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.377+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.377+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.377+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.378+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.378+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.378+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.379+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.379+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.380+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.380+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.381+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.382+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.382+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.383+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.384+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.384+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.385+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.386+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.386+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.387+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.387+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.388+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.579+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.580+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.581+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.582+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.583+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.584+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.585+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.586+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.587+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.587+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.588+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.590+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.591+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.592+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.593+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.595+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.596+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.597+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.597+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.598+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.599+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.600+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.601+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.602+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.602+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.603+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.604+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.606+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.607+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.608+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.609+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.610+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.611+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.612+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.613+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.615+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.615+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.616+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.617+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.618+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.618+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.619+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.620+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.621+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.622+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.623+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.624+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.624+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.625+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.626+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.627+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.628+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.629+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.630+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.631+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.632+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.633+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.634+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.634+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.635+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.636+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.637+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.638+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.639+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.640+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.641+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.642+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.642+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.643+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.644+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.645+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.646+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.647+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.648+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.649+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.649+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.650+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.651+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.652+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.653+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.654+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.654+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.655+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.656+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.656+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.657+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.658+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.658+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.659+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.660+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.660+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.661+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.662+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.663+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.663+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.664+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.665+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.666+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.667+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.668+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.669+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.669+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.670+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.671+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.672+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.673+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.673+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.674+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.675+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.675+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.676+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.677+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.677+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.678+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.679+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.680+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.680+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.690+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.691+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.692+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.693+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.693+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.694+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.694+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.695+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.696+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.697+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.697+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.698+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.700+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.701+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.703+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.704+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.705+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.707+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.713+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.715+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.715+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.716+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.717+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.717+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.718+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:07.719+0000] {subprocess.py:93} INFO - 25/04/28 10:47:07 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894
[2025-04-28T10:47:09.645+0000] {subprocess.py:93} INFO - 25/04/28 10:47:09 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:09.673+0000] {subprocess.py:93} INFO - 25/04/28 10:47:09 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:09.701+0000] {subprocess.py:93} INFO - 25/04/28 10:47:09 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:09.727+0000] {subprocess.py:93} INFO - 25/04/28 10:47:09 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:09.758+0000] {subprocess.py:93} INFO - 25/04/28 10:47:09 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:09.788+0000] {subprocess.py:93} INFO - 25/04/28 10:47:09 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:09.826+0000] {subprocess.py:93} INFO - 25/04/28 10:47:09 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:09.852+0000] {subprocess.py:93} INFO - 25/04/28 10:47:09 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:09.878+0000] {subprocess.py:93} INFO - 25/04/28 10:47:09 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:09.896+0000] {subprocess.py:93} INFO - 25/04/28 10:47:09 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:09.918+0000] {subprocess.py:93} INFO - 25/04/28 10:47:09 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:09.932+0000] {subprocess.py:93} INFO - 25/04/28 10:47:09 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:09.951+0000] {subprocess.py:93} INFO - 25/04/28 10:47:09 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:10.005+0000] {subprocess.py:93} INFO - 25/04/28 10:47:10 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:10.021+0000] {subprocess.py:93} INFO - 25/04/28 10:47:10 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:10.033+0000] {subprocess.py:93} INFO - 25/04/28 10:47:10 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:11.129+0000] {subprocess.py:93} INFO - 25/04/28 10:47:11 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:11.152+0000] {subprocess.py:93} INFO - 25/04/28 10:47:11 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:11.208+0000] {subprocess.py:93} INFO - 25/04/28 10:47:11 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:11.307+0000] {subprocess.py:93} INFO - 25/04/28 10:47:11 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:11.412+0000] {subprocess.py:93} INFO - 25/04/28 10:47:11 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:11.442+0000] {subprocess.py:93} INFO - 25/04/28 10:47:11 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:12.277+0000] {subprocess.py:93} INFO - 25/04/28 10:47:12 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:12.429+0000] {subprocess.py:93} INFO - 25/04/28 10:47:12 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:12.598+0000] {subprocess.py:93} INFO - 25/04/28 10:47:12 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:12.713+0000] {subprocess.py:93} INFO - 25/04/28 10:47:12 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:12.874+0000] {subprocess.py:93} INFO - 25/04/28 10:47:12 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:12.943+0000] {subprocess.py:93} INFO - 25/04/28 10:47:12 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:13.004+0000] {subprocess.py:93} INFO - 25/04/28 10:47:13 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:13.143+0000] {subprocess.py:93} INFO - 25/04/28 10:47:13 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:13.269+0000] {subprocess.py:93} INFO - 25/04/28 10:47:13 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:13.339+0000] {subprocess.py:93} INFO - 25/04/28 10:47:13 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:13.402+0000] {subprocess.py:93} INFO - 25/04/28 10:47:13 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:13.456+0000] {subprocess.py:93} INFO - 25/04/28 10:47:13 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:13.655+0000] {subprocess.py:93} INFO - 25/04/28 10:47:13 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:13.751+0000] {subprocess.py:93} INFO - 25/04/28 10:47:13 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:13.827+0000] {subprocess.py:93} INFO - 25/04/28 10:47:13 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:13.984+0000] {subprocess.py:93} INFO - 25/04/28 10:47:13 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:14.142+0000] {subprocess.py:93} INFO - 25/04/28 10:47:14 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:14.321+0000] {subprocess.py:93} INFO - 25/04/28 10:47:14 WARN HDFSBackedStateStoreProvider: The state for version 8 doesn't exist in loadedMaps. Reading snapshot file and delta files if needed...Note that this is normal for the first batch of starting query.
[2025-04-28T10:47:24.961+0000] {job.py:213} ERROR - Job heartbeat got an exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 187, in heartbeat
    self._merge_from(Job._fetch_from_db(self, session))
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 308, in _fetch_from_db
    session.merge(job)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 3056, in merge
    return self._merge(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 3136, in _merge
    merged = self.get(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2853, in get
    return self._get_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2975, in _get_impl
    return db_load_fn(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/loading.py", line 530, in load_on_pk_identity
    session.execute(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-04-28T10:50:53.355+0000] {subprocess.py:93} INFO - 25/04/28 10:50:52 WARN NettyRpcEnv: Ignored failure: java.util.concurrent.TimeoutException: Cannot receive any reply from 02173e944d7b:40633 in 120 seconds
[2025-04-28T10:50:53.323+0000] {job.py:221} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2025-04-28T10:50:53.384+0000] {subprocess.py:93} INFO - 25/04/28 10:50:53 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 204524 ms exceeds timeout 120000 ms
[2025-04-28T10:50:53.516+0000] {subprocess.py:93} INFO - 25/04/28 10:50:53 WARN SparkContext: Killing executors is not supported by current scheduler.
[2025-04-28T10:50:53.677+0000] {subprocess.py:93} INFO - 25/04/28 10:50:53 WARN Executor: Issue communicating with driver in heartbeater
[2025-04-28T10:50:53.678+0000] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-04-28T10:50:53.679+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2025-04-28T10:50:53.680+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-04-28T10:50:53.680+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2025-04-28T10:50:53.681+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2025-04-28T10:50:53.682+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-04-28T10:50:53.687+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2025-04-28T10:50:53.689+0000] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2025-04-28T10:50:53.691+0000] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2025-04-28T10:50:53.692+0000] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-04-28T10:50:53.693+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2025-04-28T10:50:53.697+0000] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-04-28T10:50:53.701+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-04-28T10:50:53.704+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-04-28T10:50:53.705+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-04-28T10:50:53.705+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-04-28T10:50:53.707+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-04-28T10:50:53.708+0000] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-04-28T10:50:53.709+0000] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-04-28T10:50:53.710+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2025-04-28T10:50:53.710+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-04-28T10:50:53.711+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-04-28T10:50:53.715+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-04-28T10:50:53.717+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-04-28T10:50:53.718+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-04-28T10:50:53.720+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-04-28T10:50:53.720+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2025-04-28T10:50:53.721+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2025-04-28T10:50:53.722+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2025-04-28T10:50:53.724+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-04-28T10:50:53.724+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-04-28T10:50:53.725+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-04-28T10:50:53.726+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-04-28T10:50:53.727+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-04-28T10:50:53.728+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-04-28T10:50:53.729+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-04-28T10:50:53.730+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2025-04-28T10:50:53.731+0000] {subprocess.py:93} INFO - 	... 3 more
[2025-04-28T10:50:53.733+0000] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@02173e944d7b:40633
[2025-04-28T10:50:53.734+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-04-28T10:50:53.735+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-04-28T10:50:53.738+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-04-28T10:50:53.741+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-04-28T10:50:53.743+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-04-28T10:50:53.744+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-04-28T10:50:53.745+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-04-28T10:50:53.747+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-04-28T10:50:53.749+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-04-28T10:50:53.751+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-04-28T10:50:53.753+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-04-28T10:50:53.754+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-04-28T10:50:53.755+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-04-28T10:50:53.756+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-04-28T10:50:53.757+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-04-28T10:50:53.758+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-04-28T10:50:53.759+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-04-28T10:50:53.760+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-04-28T10:50:53.762+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-04-28T10:50:53.763+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-04-28T10:50:53.764+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-04-28T10:50:53.765+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-04-28T10:50:53.766+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-04-28T10:50:53.767+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-04-28T10:50:53.768+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-04-28T10:50:53.770+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-04-28T10:50:53.777+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-04-28T10:50:53.781+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-04-28T10:50:53.782+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-04-28T10:50:53.783+0000] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-04-28T10:50:53.785+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-04-28T10:50:53.786+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-04-28T10:50:53.788+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-04-28T10:50:53.791+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-04-28T10:50:53.792+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-04-28T10:50:53.793+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-04-28T10:50:53.794+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-04-28T10:50:53.796+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-04-28T10:50:53.797+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-04-28T10:50:53.802+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-04-28T10:50:53.810+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-04-28T10:50:53.812+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-04-28T10:50:53.813+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-04-28T10:50:53.814+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-04-28T10:50:53.815+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-04-28T10:50:53.816+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-04-28T10:50:53.817+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-04-28T10:50:53.818+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-04-28T10:50:53.818+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-04-28T10:50:53.819+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-04-28T10:50:53.820+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-04-28T10:50:53.821+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-04-28T10:50:53.823+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-04-28T10:50:53.824+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-04-28T10:50:53.826+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-04-28T10:50:53.827+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-04-28T10:50:53.828+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-04-28T10:50:53.830+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-04-28T10:50:53.831+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-04-28T10:50:53.832+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-04-28T10:50:53.833+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-04-28T10:50:53.835+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-04-28T10:50:53.836+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-04-28T10:50:53.836+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-04-28T10:50:53.838+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-04-28T10:50:53.839+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-04-28T10:50:53.841+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-04-28T10:50:53.842+0000] {subprocess.py:93} INFO - 	... 3 more
[2025-04-28T10:50:53.843+0000] {subprocess.py:93} INFO - 25/04/28 10:50:53 ERROR Inbox: Ignoring error
[2025-04-28T10:50:53.844+0000] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-04-28T10:50:53.845+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2025-04-28T10:50:53.846+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-04-28T10:50:53.847+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-04-28T10:50:53.848+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-04-28T10:50:53.849+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-04-28T10:50:53.851+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-04-28T10:50:53.852+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-04-28T10:50:53.865+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2025-04-28T10:50:53.867+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2025-04-28T10:50:53.868+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2025-04-28T10:50:53.869+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-04-28T10:50:53.871+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-04-28T10:50:53.871+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-04-28T10:50:53.872+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-04-28T10:50:53.873+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-04-28T10:50:53.873+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-04-28T10:50:53.875+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-04-28T10:50:53.877+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2025-04-28T10:50:53.880+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-04-28T10:50:53.883+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-04-28T10:50:53.887+0000] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-04-28T10:50:53.889+0000] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@02173e944d7b:40633
[2025-04-28T10:50:53.890+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-04-28T10:50:53.891+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-04-28T10:50:53.892+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-04-28T10:50:53.893+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-04-28T10:50:53.893+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-04-28T10:50:53.894+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-04-28T10:50:53.895+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-04-28T10:50:53.896+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-04-28T10:50:53.897+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-04-28T10:50:53.906+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-04-28T10:50:53.907+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-04-28T10:50:53.910+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-04-28T10:50:53.910+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-04-28T10:50:53.913+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-04-28T10:50:53.918+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-04-28T10:50:53.919+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-04-28T10:50:53.920+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-04-28T10:50:53.921+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-04-28T10:50:53.925+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-04-28T10:50:53.926+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-04-28T10:50:53.927+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-04-28T10:50:53.928+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-04-28T10:50:53.936+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-04-28T10:50:53.945+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-04-28T10:50:53.947+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-04-28T10:50:53.948+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-04-28T10:50:53.949+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-04-28T10:50:53.950+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-04-28T10:50:53.951+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-04-28T10:50:53.952+0000] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-04-28T10:50:53.953+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-04-28T10:50:53.954+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-04-28T10:50:53.955+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-04-28T10:50:53.956+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-04-28T10:50:53.957+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-04-28T10:50:53.957+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-04-28T10:50:53.958+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-04-28T10:50:53.959+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-04-28T10:50:53.960+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-04-28T10:50:53.961+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-04-28T10:50:53.961+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-04-28T10:50:53.962+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-04-28T10:50:53.963+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-04-28T10:50:53.964+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-04-28T10:50:53.964+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-04-28T10:50:53.965+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-04-28T10:50:53.966+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-04-28T10:50:53.967+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-04-28T10:50:53.975+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-04-28T10:50:53.976+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-04-28T10:50:53.977+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-04-28T10:50:53.978+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-04-28T10:50:53.979+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-04-28T10:50:53.980+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-04-28T10:50:53.980+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-04-28T10:50:53.981+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-04-28T10:50:53.981+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-04-28T10:50:53.982+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-04-28T10:50:53.982+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-04-28T10:50:53.984+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-04-28T10:50:53.984+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-04-28T10:50:53.986+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-04-28T10:50:53.986+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-04-28T10:50:53.987+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-04-28T10:50:53.988+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-04-28T10:50:53.990+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-04-28T10:50:53.993+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-04-28T10:50:53.994+0000] {subprocess.py:93} INFO - 	... 3 more
[2025-04-28T10:50:53.996+0000] {subprocess.py:93} INFO - 25/04/28 10:50:53 WARN Executor: Issue communicating with driver in heartbeater
[2025-04-28T10:50:54.000+0000] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-04-28T10:50:54.001+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2025-04-28T10:50:54.002+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-04-28T10:50:54.006+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2025-04-28T10:50:54.007+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2025-04-28T10:50:54.008+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-04-28T10:50:54.010+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2025-04-28T10:50:54.011+0000] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2025-04-28T10:50:54.014+0000] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2025-04-28T10:50:54.015+0000] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-04-28T10:50:54.016+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2025-04-28T10:50:54.017+0000] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-04-28T10:50:54.018+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-04-28T10:50:54.019+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-04-28T10:50:54.021+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-04-28T10:50:54.025+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-04-28T10:50:54.026+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-04-28T10:50:54.027+0000] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-04-28T10:50:54.028+0000] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-04-28T10:50:54.029+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2025-04-28T10:50:54.030+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-04-28T10:50:54.031+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-04-28T10:50:54.031+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-04-28T10:50:54.032+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-04-28T10:50:54.033+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-04-28T10:50:54.034+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-04-28T10:50:54.034+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2025-04-28T10:50:54.035+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2025-04-28T10:50:54.035+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2025-04-28T10:50:54.036+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-04-28T10:50:54.039+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-04-28T10:50:54.044+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-04-28T10:50:54.045+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-04-28T10:50:54.045+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-04-28T10:50:54.046+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-04-28T10:50:54.046+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-04-28T10:50:54.047+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2025-04-28T10:50:54.048+0000] {subprocess.py:93} INFO - 	... 3 more
[2025-04-28T10:50:54.049+0000] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@02173e944d7b:40633
[2025-04-28T10:50:54.049+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-04-28T10:50:54.050+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-04-28T10:50:54.050+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-04-28T10:50:54.053+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-04-28T10:50:54.053+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-04-28T10:50:54.055+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-04-28T10:50:54.057+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-04-28T10:50:54.062+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-04-28T10:50:54.067+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-04-28T10:50:54.080+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-04-28T10:50:54.081+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-04-28T10:50:54.082+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-04-28T10:50:54.083+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-04-28T10:50:54.085+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-04-28T10:50:54.086+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-04-28T10:50:54.092+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-04-28T10:50:54.093+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-04-28T10:50:54.096+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-04-28T10:50:54.101+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-04-28T10:50:54.108+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-04-28T10:50:54.110+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-04-28T10:50:54.112+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-04-28T10:50:54.115+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-04-28T10:50:54.117+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-04-28T10:50:54.118+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-04-28T10:50:54.119+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-04-28T10:50:54.120+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-04-28T10:50:54.124+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-04-28T10:50:54.126+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-04-28T10:50:54.129+0000] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-04-28T10:50:54.132+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-04-28T10:50:54.134+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-04-28T10:50:54.135+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-04-28T10:50:54.136+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-04-28T10:50:54.137+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-04-28T10:50:54.138+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-04-28T10:50:54.140+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-04-28T10:50:54.143+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-04-28T10:50:54.153+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-04-28T10:50:54.156+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-04-28T10:50:54.158+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-04-28T10:50:54.159+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-04-28T10:50:54.163+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-04-28T10:50:54.164+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-04-28T10:50:54.165+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-04-28T10:50:54.167+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-04-28T10:50:54.168+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-04-28T10:50:54.170+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-04-28T10:50:54.171+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-04-28T10:50:54.172+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-04-28T10:50:54.172+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-04-28T10:50:54.173+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-04-28T10:50:54.173+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-04-28T10:50:54.174+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-04-28T10:50:54.177+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-04-28T10:50:54.178+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-04-28T10:50:54.179+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-04-28T10:50:54.181+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-04-28T10:50:54.183+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-04-28T10:50:54.186+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-04-28T10:50:54.187+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-04-28T10:50:54.188+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-04-28T10:50:54.190+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-04-28T10:50:54.191+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-04-28T10:50:54.192+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-04-28T10:50:54.195+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-04-28T10:50:54.197+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-04-28T10:50:54.199+0000] {subprocess.py:93} INFO - 	... 3 more
[2025-04-28T10:50:54.201+0000] {subprocess.py:93} INFO - 25/04/28 10:50:53 ERROR Inbox: Ignoring error
[2025-04-28T10:50:54.203+0000] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-04-28T10:50:54.204+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2025-04-28T10:50:54.214+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-04-28T10:50:54.216+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-04-28T10:50:54.217+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-04-28T10:50:54.219+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-04-28T10:50:54.221+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-04-28T10:50:54.222+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-04-28T10:50:54.224+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2025-04-28T10:50:54.226+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2025-04-28T10:50:54.228+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2025-04-28T10:50:54.230+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-04-28T10:50:54.232+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-04-28T10:50:54.233+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-04-28T10:50:54.237+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-04-28T10:50:54.239+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-04-28T10:50:54.240+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-04-28T10:50:54.241+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-04-28T10:50:54.242+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2025-04-28T10:50:54.243+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-04-28T10:50:54.244+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-04-28T10:50:54.245+0000] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-04-28T10:50:54.247+0000] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@02173e944d7b:40633
[2025-04-28T10:50:54.252+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-04-28T10:50:54.254+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-04-28T10:50:54.257+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-04-28T10:50:54.258+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-04-28T10:50:54.258+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-04-28T10:50:54.259+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-04-28T10:50:54.260+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-04-28T10:50:54.262+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-04-28T10:50:54.264+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-04-28T10:50:54.265+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-04-28T10:50:54.266+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-04-28T10:50:54.270+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-04-28T10:50:54.272+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-04-28T10:50:54.273+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-04-28T10:50:54.278+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-04-28T10:50:54.279+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-04-28T10:50:54.281+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-04-28T10:50:54.282+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-04-28T10:50:54.283+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-04-28T10:50:54.286+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-04-28T10:50:54.287+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-04-28T10:50:54.288+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-04-28T10:50:54.290+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-04-28T10:50:54.295+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-04-28T10:50:54.296+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-04-28T10:50:54.302+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-04-28T10:50:54.309+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-04-28T10:50:54.311+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-04-28T10:50:54.312+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-04-28T10:50:54.313+0000] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-04-28T10:50:54.314+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-04-28T10:50:54.315+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-04-28T10:50:54.316+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-04-28T10:50:54.318+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-04-28T10:50:54.320+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-04-28T10:50:54.321+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-04-28T10:50:54.321+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-04-28T10:50:54.322+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-04-28T10:50:54.327+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-04-28T10:50:54.330+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-04-28T10:50:54.332+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-04-28T10:50:54.334+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-04-28T10:50:54.336+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-04-28T10:50:54.337+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-04-28T10:50:54.341+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-04-28T10:50:54.342+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-04-28T10:50:54.344+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-04-28T10:50:54.348+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-04-28T10:50:54.351+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-04-28T10:50:54.352+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-04-28T10:50:54.353+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-04-28T10:50:54.355+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-04-28T10:50:54.356+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-04-28T10:50:54.357+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-04-28T10:50:54.358+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-04-28T10:50:54.359+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-04-28T10:50:54.360+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-04-28T10:50:54.360+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-04-28T10:50:54.361+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-04-28T10:50:54.362+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-04-28T10:50:54.364+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-04-28T10:50:54.366+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-04-28T10:50:54.368+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-04-28T10:50:54.370+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-04-28T10:50:54.373+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-04-28T10:50:54.377+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-04-28T10:50:54.378+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-04-28T10:50:54.378+0000] {subprocess.py:93} INFO - 	... 3 more
[2025-04-28T10:50:54.380+0000] {subprocess.py:93} INFO - 25/04/28 10:50:53 ERROR Inbox: Ignoring error
[2025-04-28T10:50:54.383+0000] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-04-28T10:50:54.389+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2025-04-28T10:50:54.392+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-04-28T10:50:54.393+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-04-28T10:50:54.394+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-04-28T10:50:54.395+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-04-28T10:50:54.396+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-04-28T10:50:54.398+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-04-28T10:50:54.400+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2025-04-28T10:50:54.406+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2025-04-28T10:50:54.408+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2025-04-28T10:50:54.410+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-04-28T10:50:54.411+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-04-28T10:50:54.413+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-04-28T10:50:54.414+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-04-28T10:50:54.415+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-04-28T10:50:54.416+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-04-28T10:50:54.417+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-04-28T10:50:54.420+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2025-04-28T10:50:54.421+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-04-28T10:50:54.423+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-04-28T10:50:54.424+0000] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-04-28T10:50:54.425+0000] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@02173e944d7b:40633
[2025-04-28T10:50:54.425+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-04-28T10:50:54.426+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-04-28T10:50:54.427+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-04-28T10:50:54.428+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-04-28T10:50:54.429+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-04-28T10:50:54.430+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-04-28T10:50:54.430+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-04-28T10:50:54.431+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-04-28T10:50:54.432+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2025-04-28T10:50:54.433+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2025-04-28T10:50:54.436+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2025-04-28T10:50:54.102+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2025-04-28T10:50:54.104+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2025-04-28T10:50:54.105+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap(Future.scala:306)
[2025-04-28T10:50:54.107+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap$(Future.scala:306)
[2025-04-28T10:50:54.109+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2025-04-28T10:50:54.112+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2025-04-28T10:50:54.115+0000] {subprocess.py:93} INFO - 	... 19 more
[2025-04-28T10:50:54.116+0000] {subprocess.py:93} INFO - 25/04/28 10:50:53 WARN Executor: Issue communicating with driver in heartbeater
[2025-04-28T10:50:54.118+0000] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-04-28T10:50:54.119+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2025-04-28T10:50:54.120+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-04-28T10:50:54.121+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2025-04-28T10:50:54.122+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2025-04-28T10:50:54.125+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-04-28T10:50:54.129+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2025-04-28T10:50:54.130+0000] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2025-04-28T10:50:54.134+0000] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2025-04-28T10:50:54.141+0000] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-04-28T10:50:54.143+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2025-04-28T10:50:54.145+0000] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-04-28T10:50:54.148+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-04-28T10:50:54.152+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-04-28T10:50:54.165+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-04-28T10:50:54.176+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-04-28T10:50:54.179+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-04-28T10:50:54.194+0000] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-04-28T10:50:54.203+0000] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-04-28T10:50:54.207+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2025-04-28T10:50:54.209+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-04-28T10:50:54.211+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-04-28T10:50:54.212+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-04-28T10:50:54.217+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-04-28T10:50:54.218+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-04-28T10:50:54.220+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-04-28T10:50:54.221+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2025-04-28T10:50:54.222+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2025-04-28T10:50:54.223+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2025-04-28T10:50:54.224+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-04-28T10:50:54.225+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-04-28T10:50:54.225+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-04-28T10:50:54.227+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-04-28T10:50:54.228+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-04-28T10:50:54.229+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-04-28T10:50:54.230+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-04-28T10:50:54.231+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2025-04-28T10:50:54.233+0000] {subprocess.py:93} INFO - 	... 3 more
[2025-04-28T10:50:54.241+0000] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@02173e944d7b:40633
[2025-04-28T10:50:54.242+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-04-28T10:50:54.248+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-04-28T10:50:54.252+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-04-28T10:50:54.253+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-04-28T10:50:54.255+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-04-28T10:50:54.256+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-04-28T10:50:54.261+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-04-28T10:50:54.265+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-04-28T10:50:54.267+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2025-04-28T10:50:54.268+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2025-04-28T10:50:54.269+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2025-04-28T10:50:54.270+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2025-04-28T10:50:54.271+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2025-04-28T10:50:54.272+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap(Future.scala:306)
[2025-04-28T10:50:54.273+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Future.flatMap$(Future.scala:306)
[2025-04-28T10:50:54.274+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2025-04-28T10:50:54.274+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2025-04-28T10:50:54.276+0000] {subprocess.py:93} INFO - 	... 19 more
[2025-04-28T10:50:54.277+0000] {subprocess.py:93} INFO - 25/04/28 10:50:53 ERROR Inbox: Ignoring error
[2025-04-28T10:50:54.278+0000] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-04-28T10:50:54.279+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2025-04-28T10:50:54.281+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-04-28T10:50:54.282+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-04-28T10:50:54.283+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-04-28T10:50:54.285+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-04-28T10:50:54.286+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-04-28T10:50:54.287+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-04-28T10:50:54.288+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2025-04-28T10:50:54.290+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2025-04-28T10:50:54.292+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2025-04-28T10:50:54.302+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-04-28T10:50:54.308+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-04-28T10:50:54.309+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-04-28T10:50:54.309+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-04-28T10:50:54.310+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-04-28T10:50:54.312+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-04-28T10:50:54.313+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-04-28T10:50:54.326+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2025-04-28T10:50:54.340+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-04-28T10:50:54.341+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-04-28T10:50:54.342+0000] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-04-28T10:50:54.348+0000] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@02173e944d7b:40633
[2025-04-28T10:50:54.350+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-04-28T10:50:54.352+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-04-28T10:50:54.353+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-04-28T10:50:54.356+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-04-28T10:50:54.359+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-04-28T10:50:54.360+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-04-28T10:50:54.361+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-04-28T10:50:54.362+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-04-28T10:50:54.363+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-04-28T10:50:54.368+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-04-28T10:50:54.369+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-04-28T10:50:54.372+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-04-28T10:50:54.373+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-04-28T10:50:54.374+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-04-28T10:50:54.377+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-04-28T10:50:54.379+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-04-28T10:50:54.380+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-04-28T10:50:54.381+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-04-28T10:50:54.383+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-04-28T10:50:54.387+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-04-28T10:50:54.394+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-04-28T10:50:54.403+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-04-28T10:50:54.413+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-04-28T10:50:54.420+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-04-28T10:50:54.433+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-04-28T10:50:54.435+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-04-28T10:50:54.436+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-04-28T10:50:54.437+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-04-28T10:50:54.439+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-04-28T10:50:54.440+0000] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-04-28T10:50:54.447+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-04-28T10:50:54.450+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-04-28T10:50:54.453+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-04-28T10:50:54.455+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-04-28T10:50:54.458+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-04-28T10:50:54.462+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-04-28T10:50:54.473+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-04-28T10:50:54.476+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-04-28T10:50:54.480+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-04-28T10:50:54.481+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-04-28T10:50:54.483+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-04-28T10:50:54.484+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-04-28T10:50:54.485+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-04-28T10:50:54.487+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-04-28T10:50:54.488+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-04-28T10:50:54.489+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-04-28T10:50:54.491+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-04-28T10:50:54.493+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-04-28T10:50:54.494+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-04-28T10:50:54.495+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-04-28T10:50:54.497+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-04-28T10:50:54.499+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-04-28T10:50:54.503+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-04-28T10:50:54.504+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-04-28T10:50:54.507+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-04-28T10:50:54.510+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-04-28T10:50:54.511+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-04-28T10:50:54.513+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-04-28T10:50:54.514+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-04-28T10:50:54.516+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-04-28T10:50:54.517+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-04-28T10:50:54.520+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-04-28T10:50:54.521+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-04-28T10:50:54.522+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-04-28T10:50:54.523+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-04-28T10:50:54.524+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-04-28T10:50:54.525+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-04-28T10:50:54.526+0000] {subprocess.py:93} INFO - 	... 3 more
[2025-04-28T10:50:54.528+0000] {subprocess.py:93} INFO - 25/04/28 10:50:53 WARN Executor: Issue communicating with driver in heartbeater
[2025-04-28T10:50:54.530+0000] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-04-28T10:50:54.536+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2025-04-28T10:50:54.571+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-04-28T10:50:54.573+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2025-04-28T10:50:54.575+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2025-04-28T10:50:54.576+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-04-28T10:50:54.578+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2025-04-28T10:50:54.580+0000] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2025-04-28T10:50:54.584+0000] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2025-04-28T10:50:54.585+0000] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-04-28T10:50:54.586+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2025-04-28T10:50:54.587+0000] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-04-28T10:50:54.588+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-04-28T10:50:54.591+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2025-04-28T10:50:54.594+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2025-04-28T10:50:54.596+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-04-28T10:50:54.597+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-04-28T10:50:54.598+0000] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-04-28T10:50:54.600+0000] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-04-28T10:50:54.601+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2025-04-28T10:50:54.602+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-04-28T10:50:54.604+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-04-28T10:50:54.611+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-04-28T10:50:54.613+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-04-28T10:50:54.614+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-04-28T10:50:54.615+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-04-28T10:50:54.616+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2025-04-28T10:50:54.617+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2025-04-28T10:50:54.618+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2025-04-28T10:50:54.619+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-04-28T10:50:54.620+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-04-28T10:50:54.622+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-04-28T10:50:54.629+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-04-28T10:50:54.631+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-04-28T10:50:54.632+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-04-28T10:50:54.633+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-04-28T10:50:54.634+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2025-04-28T10:50:54.635+0000] {subprocess.py:93} INFO - 	... 3 more
[2025-04-28T10:50:54.636+0000] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@02173e944d7b:40633
[2025-04-28T10:50:54.638+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-04-28T10:50:54.639+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-04-28T10:50:54.640+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-04-28T10:50:54.641+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-04-28T10:50:54.644+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-04-28T10:50:54.647+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-04-28T10:50:54.651+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-04-28T10:50:54.653+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-04-28T10:50:54.655+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-04-28T10:50:54.657+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-04-28T10:50:54.659+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-04-28T10:50:54.661+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-04-28T10:50:54.662+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-04-28T10:50:54.664+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-04-28T10:50:54.665+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-04-28T10:50:54.666+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-04-28T10:50:54.668+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-04-28T10:50:54.669+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-04-28T10:50:54.671+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-04-28T10:50:54.671+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-04-28T10:50:54.673+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-04-28T10:50:54.675+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-04-28T10:50:54.676+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-04-28T10:50:54.677+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-04-28T10:50:54.679+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-04-28T10:50:54.681+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-04-28T10:50:54.682+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-04-28T10:50:54.684+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-04-28T10:50:54.685+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-04-28T10:50:54.687+0000] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-04-28T10:50:54.688+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-04-28T10:50:54.690+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-04-28T10:50:54.691+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-04-28T10:50:54.692+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-04-28T10:50:54.692+0000] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-04-28T10:50:54.694+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-04-28T10:50:54.695+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-04-28T10:50:54.697+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-04-28T10:50:54.699+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-04-28T10:50:54.701+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-04-28T10:50:54.702+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-04-28T10:50:54.703+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-04-28T10:50:54.705+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-04-28T10:50:54.706+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-04-28T10:50:54.708+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-04-28T10:50:54.709+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-04-28T10:50:54.711+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-04-28T10:50:54.712+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-04-28T10:50:54.713+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-04-28T10:50:54.715+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-04-28T10:50:54.717+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-04-28T10:50:54.719+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-04-28T10:50:54.720+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-04-28T10:50:54.721+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-04-28T10:50:54.722+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-04-28T10:50:54.724+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-04-28T10:50:54.725+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-04-28T10:50:54.726+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-04-28T10:50:54.727+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-04-28T10:50:54.729+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-04-28T10:50:54.729+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-04-28T10:50:54.730+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-04-28T10:50:54.733+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-04-28T10:50:54.735+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-04-28T10:50:54.736+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-04-28T10:50:54.737+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-04-28T10:50:54.738+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-04-28T10:50:54.740+0000] {subprocess.py:93} INFO - 	... 3 more
[2025-04-28T10:50:54.742+0000] {subprocess.py:93} INFO - 25/04/28 10:50:53 ERROR Inbox: Ignoring error
[2025-04-28T10:50:54.746+0000] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-04-28T10:50:54.747+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2025-04-28T10:50:54.748+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-04-28T10:50:54.749+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-04-28T10:50:54.750+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-04-28T10:50:54.751+0000] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-04-28T10:50:54.752+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-04-28T10:50:54.753+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-04-28T10:50:54.755+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2025-04-28T10:50:54.757+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2025-04-28T10:50:54.759+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2025-04-28T10:50:54.763+0000] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-04-28T10:50:54.764+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-04-28T10:50:54.765+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-04-28T10:50:54.768+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-04-28T10:50:54.769+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-04-28T10:50:54.773+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-04-28T10:50:54.780+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
[2025-04-28T10:50:54.782+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2025-04-28T10:50:54.784+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2025-04-28T10:50:54.786+0000] {subprocess.py:93} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2025-04-28T10:50:54.787+0000] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Thread.java:840)
[2025-04-28T10:50:54.792+0000] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@02173e944d7b:40633
[2025-04-28T10:50:54.795+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-04-28T10:50:54.798+0000] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-04-28T10:50:54.802+0000] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-04-28T10:50:54.803+0000] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
